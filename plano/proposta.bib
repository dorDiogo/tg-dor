@inproceedings{Schleimer2003,
address = {New York, New York, USA},
author = {Schleimer, Saul and Wilkerson, Daniel S. and Aiken, Alex},
booktitle = {Proceedings of the 2003 ACM SIGMOD international conference on on Management of data - SIGMOD '03},
doi = {10.1145/872757.872770},
file = {:home/paulo/Documents/work/bib/files/Schleimer, Wilkerson, Aiken - 2003 - Winnowing.pdf:pdf},
isbn = {158113634X},
pages = {76},
publisher = {ACM Press},
title = {{Winnowing}},
url = {http://portal.acm.org/citation.cfm?doid=872757.872770},
year = {2003}
}
@article{Orenstein2017,
abstract = {With the rapidly increasing volume of deep sequencing data, more efficient algorithms and data structures are needed. Minimizers are a central recent paradigm that has improved various sequence analysis tasks, including hashing for faster read overlap detection, sparse suffix arrays for creating smaller indexes, and Bloom filters for speeding up sequence search. Here, we propose an alternative paradigm that can lead to substantial further improvement in these and other tasks. For integers k and L {\textgreater} k, we say that a set of k-mers is a universal hitting set (UHS) if every possible L-long sequence must contain a k-mer from the set. We develop a heuristic called DOCKS to find a compact UHS, which works in two phases: The first phase is solved optimally, and for the second we propose several efficient heuristics, trading set size for speed and memory. The use of heuristics is motivated by showing the NP-hardness of a closely related problem. We show that DOCKS works well in practice and produces UHSs that are very close to a theoretical lower bound. We present results for various values of k and L and by applying them to real genomes show that UHSs indeed improve over minimizers. In particular, DOCKS uses less than 30{\%} of the 10-mers needed to span the human genome compared to minimizers. The software and computed UHSs are freely available at github.com/Shamir-Lab/DOCKS/ and acgt.cs.tau.ac.il/docks/, respectively.},
author = {Orenstein, Yaron and Pellow, David and Mar{\c{c}}ais, Guillaume and Shamir, Ron and Kingsford, Carl},
doi = {10.1371/journal.pcbi.1005777},
editor = {Raphael, Benjamin J.},
file = {:home/paulo/Documents/work/bib/files/Orenstein et al. - 2017 - Designing small universal k-mer hitting sets for improved analysis of high-throughput sequencing.pdf:pdf},
issn = {1553-7358},
journal = {PLOS Computational Biology},
month = {oct},
number = {10},
pages = {e1005777},
publisher = {Public Library of Science},
title = {{Designing small universal k-mer hitting sets for improved analysis of high-throughput sequencing}},
url = {https://dx.plos.org/10.1371/journal.pcbi.1005777},
volume = {13},
year = {2017}
}
@article{Marcais2017,
author = {Mar{\c{c}}ais, Guillaume and Pellow, David and Bork, Daniel and Orenstein, Yaron and Shamir, Ron and Kingsford, Carl},
doi = {10.1093/bioinformatics/btx235},
file = {:home/paulo/Documents/work/bib/files/Mar{\c{c}}ais et al. - 2017 - Improving the performance of minimizers and winnowing schemes.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
month = {jul},
number = {14},
pages = {i110--i117},
publisher = {Oxford University Press},
title = {{Improving the performance of minimizers and winnowing schemes}},
url = {https://academic.oup.com/bioinformatics/article/33/14/i110/3953951},
volume = {33},
year = {2017}
}
@article{Roberts2004,
author = {Roberts, M. and Hayes, W. and Hunt, B. R. and Mount, S. M. and Yorke, J. A.},
doi = {10.1093/bioinformatics/bth408},
file = {:home/paulo/Documents/work/bib/files/Roberts et al. - 2004 - Reducing storage requirements for biological sequence comparison.pdf:pdf},
issn = {1367-4803},
journal = {Bioinformatics},
month = {dec},
number = {18},
pages = {3363--3369},
publisher = {Oxford University Press},
title = {{Reducing storage requirements for biological sequence comparison}},
url = {https://academic.oup.com/bioinformatics/article-lookup/doi/10.1093/bioinformatics/bth408},
volume = {20},
year = {2004}
}

@article{Li2016,
    author = {Li, Heng},
    title = "{Minimap and miniasm: fast mapping and de novo assembly for noisy long sequences}",
    journal = {Bioinformatics},
    volume = {32},
    number = {14},
    pages = {2103-2110},
    year = {2016},
    month = {03},
    abstract = "{Motivation: Single Molecule Real-Time (SMRT) sequencing technology and Oxford Nanopore technologies (ONT) produce reads over 10 kb in length, which have enabled high-quality genome assembly at an affordable cost. However, at present, long reads have an error rate as high as 10–15\\%. Complex and computationally intensive pipelines are required to assemble such reads.Results: We present a new mapper, minimap and a de novo assembler, miniasm, for efficiently mapping and assembling SMRT and ONT reads without an error correction stage. They can often assemble a sequencing run of bacterial data into a single contig in a few minutes, and assemble 45-fold Caenorhabditis elegans data in 9 min, orders of magnitude faster than the existing pipelines, though the consensus sequence error rate is as high as raw reads. We also introduce a pairwise read mapping format and a graphical fragment assembly format, and demonstrate the interoperability between ours and current tools.Availability and implementation:https://github.com/lh3/minimap and https://github.com/lh3/miniasmContact:hengli@broadinstitute.orgSupplementary information:Supplementary data are available at Bioinformatics online.}",
    issn = {1367-4803},
    doi = {10.1093/bioinformatics/btw152},
    url = {https://doi.org/10.1093/bioinformatics/btw152},
    eprint = {http://oup.prod.sis.lan/bioinformatics/article-pdf/32/14/2103/19567911/btw152.pdf},
}

@Article{Fernandes2011,
author="Fernandes, Francisco
and da Fonseca, Paulo GS
and Russo, Luis MS
and Oliveira, Arlindo L.
and Freitas, Ana T.",
title="Efficient alignment of pyrosequencing reads for re-sequencing applications",
journal="BMC Bioinformatics",
year="2011",
month="May",
day="16",
volume="12",
number="1",
pages="163",
abstract="Over the past few years, new massively parallel DNA sequencing technologies have emerged. These platforms generate massive amounts of data per run, greatly reducing the cost of DNA sequencing. However, these techniques also raise important computational difficulties mostly due to the huge volume of data produced, but also because of some of their specific characteristics such as read length and sequencing errors. Among the most critical problems is that of efficiently and accurately mapping reads to a reference genome in the context of re-sequencing projects.",
issn="1471-2105",
doi="10.1186/1471-2105-12-163",
url="https://doi.org/10.1186/1471-2105-12-163"
}
